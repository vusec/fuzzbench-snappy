# FuzzBench Fork for Snappy Evaluation

This FuzzBench fork contains the code necessary to run all the experiments in
the paper "Snappy: Efficient Fuzzing with Adaptive and Mutable Snapshots". The
code for the fuzzer can be found in [this][snappy] repository.

This fork contains three additional fuzzers (`angora`, `snappy`,
`snappy_no_exit`) and two additional benchmarks (`binutils_fuzz_objdump`,
`sqlite3_shell`).

While the original [FuzzBench documentation][fuzzbench-docs] can be used to
solve most of the issues that may araise, this fork requires additional steps to
set up the kernel module used for snapshotting. This module is stored in a
[separate repository][snapshot-lkm].

[fuzzbench-docs]: https://google.github.io/fuzzbench/
[snapshot-lkm]: https://github.com/vusec/AFL-Snapshot-LKM-snappy

The snapshotting kernel module has only been tested on Ubuntu 20.04 with kernel
5.15, so this is the recommended setup to use. FuzzBench itself does not impose
further restrictions, apart from requiring Python 3.9 and Docker, which are both
available for that distribution.


## Preparation

Assuming you are running Ubuntu 20.04, you can install kernel 5.15 as follows:

```bash
sudo add-apt-repository ppa:canonical-kernel-team/proposed
sudo apt update
sudo apt upgrade
sudo apt install linux-headers-5.15.*-*-generic linux-image-5.15.*-*-generic
```

Make sure to reboot and check with `uname -r` that you are running the right
kernel version.

Then, you should build and load the snapshotting kernel module from its
[repository][snapshot-lkm]. Detailed instructions are provided there. You can
verify that the module was successfully loaded by checking if
`/dev/afl_snapshot` is present.

After this, you can install Docker following the instructions in the [official
documentation][docker-docs].

[docker-docs]: https://docs.docker.com/engine/install/ubuntu/

Finally, you should install the following packages to be able to run FuzzBench:

```bash
sudo apt install python3.9 python3.9-dev python3.9-venv libpq-dev
```

The setup can then be finished following the FuzzBench
[documentation][fuzzbench-prereq].

[fuzzbench-prereq]: https://google.github.io/fuzzbench/getting-started/prerequisites/


## Running experiments

In order to run experiments you will need a configuration file. The one we used
for our experiments is the following:

```yaml
# The number of trials of a fuzzer-benchmark pair.
trials: 16

# The amount of time in seconds that each trial is run for.
# 24 hours = 24 * 60 * 60 = 86400
max_total_time: 86400

# The location of the docker registry.
# FIXME: Support custom docker registry.
# See https://github.com/google/fuzzbench/issues/777
docker_registry: gcr.io/fuzzbench

# The local experiment folder that will store most of the experiment data.
# Please use an absolute path.
experiment_filestore: /home/ubuntu/snappy-experiments/experiment-data

# The local report folder where HTML reports and summary data will be stored.
# Please use an absolute path.
report_filestore: /home/ubuntu/snappy-experiments/report-data

# Flag that indicates this is a local experiment.
local_experiment: true

exposed_devices:
  - /dev/afl_snapshot
```

You can then start experiments using the following command line:

```bash
PYTHONPATH=. python3 experiment/run_experiment.py \
  --experiment-config ${config_file} \
  --concurrent-builds 2 \
  --runners-cpus 32 \
  --measurers-cpus 32 \
  --experiment-name ${experiment_name} \
  --fuzzers angora snappy \
  --benchmarks ${benchmark_list[@]}
```

It is important to note that you should avoid committing more cores than the
total amount available on your machine. That command is for a machine with 64
cores. If you run out of RAM while building, you may want to reduce the
concurrent builds to 1. Make sure to use only benchmarks that are listed in the
paper, the others are not supported.


## Results analysis

Albeit graphically different from the plots in the paper, FuzzBench will
automatically generate an HTML report with coverage data.

The other data, which was used for the speed plots and other statistics, can be
extracted with the following two scripts, which are part of the [fuzzer
repository][snappy].

```bash
python3 ${snappy_root}/tools/extract_angora_logs.py \
  ${experiment_filestore}/${experiment_name} \
  ${output_file}.csv.gz

python3 ${snappy_root}/tools/experiment_stats.py \
  ${experiment_filestore}/${experiment_name}
```

The first script simply extracts the logs produced by the fuzzer from the
archives and stores it in a format that can be easily processed with `pandas`.
The second, instead, processes the histograms generated by the predictor and
stores the results in a `paper_stats.csv` file, inside the experiment folder.
This file is used to generate the statistics used in our tables.

[snappy]: https://github.com/vusec/snappy
